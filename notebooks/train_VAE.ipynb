{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.VAE_for_RUL_pediction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_latent_space(encoder, data, targets=[], epoch='Final', save=False, show=True):\n",
    "    z, _, _  = encoder.predict(data)\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    if len(targets)>0:\n",
    "        plt.scatter(z[:, 0], z[:, 1], c=targets)\n",
    "    else:\n",
    "        plt.scatter(z[:, 0], z[:, 1])\n",
    "    plt.xlabel('z - dim 1')\n",
    "    plt.ylabel('z - dim 2')\n",
    "    plt.colorbar()\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save:\n",
    "        plt.savefig('./images/latent_space_epoch'+str(epoch)+'.png')\n",
    "    return z\n",
    "\n",
    "def get_data(dataset, sensors, sequence_length, alpha, threshold):\n",
    "\t# files\n",
    "\tdir_path = '../data/'\n",
    "\ttrain_file = 'train_'+dataset+'.txt'\n",
    "\ttest_file = 'test_'+dataset+'.txt'\n",
    "    # columns\n",
    "\tindex_names = ['unit_nr', 'time_cycles']\n",
    "\tsetting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "\tsensor_names = ['s_{}'.format(i+1) for i in range(0,21)]\n",
    "\tcol_names = index_names + setting_names + sensor_names\n",
    "    # data readout\n",
    "\ttrain = pd.read_csv((dir_path+train_file), sep=r'\\s+', header=None, \n",
    "\t\t\t\t\t names=col_names)\n",
    "\ttest = pd.read_csv((dir_path+test_file), sep=r'\\s+', header=None, \n",
    "\t\t\t\t\t names=col_names)\n",
    "\ty_test = pd.read_csv((dir_path+'RUL_'+dataset+'.txt'), sep=r'\\s+', header=None, \n",
    "\t\t\t\t\t names=['RemainingUsefulLife'])\n",
    "\n",
    "    # create RUL values according to the piece-wise target function\n",
    "\ttrain = add_remaining_useful_life(train)\n",
    "\ttrain['RUL'].clip(upper=threshold, inplace=True)\n",
    "\n",
    "    # remove unused sensors\n",
    "\tdrop_sensors = [element for element in sensor_names if element not in sensors]\n",
    "\n",
    "    # scale with respect to the operating condition\n",
    "\tX_train_pre = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
    "\tX_test_pre = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
    "\tX_train_pre, X_test_pre = condition_scaler(X_train_pre, X_test_pre, sensors)\n",
    "\n",
    "    # exponential smoothing\n",
    "\tX_train_pre= exponential_smoothing(X_train_pre, sensors, 0, alpha)\n",
    "\tX_test_pre = exponential_smoothing(X_test_pre, sensors, 0, alpha)\n",
    "\n",
    "\t# train-val split\n",
    "\tgss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)\n",
    "\t# generate the train/val for *each* sample -> for that we iterate over the train and val units we want\n",
    "\t# this is a for that iterates only once and in that iterations at the same time iterates over all the values we want,\n",
    "\t# i.e. train_unit and val_unit are not a single value but a set of training/vali units\n",
    "\tfor train_unit, val_unit in gss.split(X_train_pre['unit_nr'].unique(), groups=X_train_pre['unit_nr'].unique()): \n",
    "\t\ttrain_unit = X_train_pre['unit_nr'].unique()[train_unit]  # gss returns indexes and index starts at 1\n",
    "\t\tval_unit = X_train_pre['unit_nr'].unique()[val_unit]\n",
    "\n",
    "\t\tx_train = gen_data_wrapper(X_train_pre, sequence_length, sensors, train_unit)\n",
    "\t\ty_train = gen_label_wrapper(X_train_pre, sequence_length, ['RUL'], train_unit)\n",
    "\t\t\n",
    "\t\tx_val = gen_data_wrapper(X_train_pre, sequence_length, sensors, val_unit)\n",
    "\t\ty_val = gen_label_wrapper(X_train_pre, sequence_length, ['RUL'], val_unit)\n",
    "\n",
    "\t# create sequences for test \n",
    "\ttest_gen = (list(gen_test_data(X_test_pre[X_test_pre['unit_nr']==unit_nr], sequence_length, sensors, -99.))\n",
    "\t\t\t   for unit_nr in X_test_pre['unit_nr'].unique())\n",
    "\tx_test = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "\t\n",
    "\treturn x_train, y_train, x_val, y_val, x_test, y_test['RemainingUsefulLife']\n",
    "\n",
    "class save_latent_space_viz(Callback):\n",
    "\tdef __init__(self, model, data, target):\n",
    "\t\tself.model = model\n",
    "\t\tself.data = data\n",
    "\t\tself.target = target\n",
    "\t\n",
    "\tdef on_train_begin(self, logs={}):\n",
    "\t\tself.best_val_loss = 100000\n",
    "\t\t\n",
    "\tdef on_epoch_end(self, epoch, logs=None):\n",
    "\t\tencoder = self.model.layers[0]\n",
    "\t\tif logs.get('val_loss') < self.best_val_loss:\n",
    "\t\t\tself.best_val_loss = logs.get('val_loss')\n",
    "\t\t\tviz_latent_space(encoder, self.data, self.target, epoch, True, False)\n",
    "\t\n",
    "def get_callbacks(model, data, target):\n",
    "\tmodel_callbacks = [\n",
    "\t\tEarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30),\n",
    "        ModelCheckpoint(filepath='./checkpoints/checkpoint',monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "\t\tTensorBoard(log_dir='./logs'),\n",
    "        save_latent_space_viz(model, data, target)\n",
    "\t]\n",
    "\treturn model_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"FD001\"\n",
    "# sensors to work with: T30, T50, P30, PS30, phi\n",
    "sensors = ['s_3', 's_4', 's_7', 's_11', 's_12']\n",
    "# windows length\n",
    "sequence_length = 30\n",
    "# smoothing intensity\n",
    "alpha = 0.1\n",
    "# max RUL\n",
    "threshold = 125   \n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_data(dataset, sensors, \n",
    "                sequence_length, alpha, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)  [(None, 30, 5)]              0         []                            \n",
      "                                                                                                  \n",
      " masking_1 (Masking)         (None, 30, 5)                0         ['encoder_input[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 600)                  734400    ['masking_1[0][0]']           \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    1202      ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 2)                    1202      ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " sampling_1 (Sampling)       (None, 2)                    0         ['dense_3[0][0]',             \n",
      "                                                                     'dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 736804 (2.81 MB)\n",
      "Trainable params: 736804 (2.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling_reg (InputLayer  [(None, 2)]               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               600       \n",
      "                                                                 \n",
      " reg_output (Dense)          (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801 (3.13 KB)\n",
      "Trainable params: 801 (3.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "timesteps = x_train.shape[1]\n",
    "input_dim = x_train.shape[2]\n",
    "intermediate_dim = 300\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 10\n",
    "optimizer = 'adam'\n",
    "\t\n",
    "RVE = create_model(timesteps, \n",
    "\t\tinput_dim, \n",
    "\t\tintermediate_dim, \n",
    "\t\tbatch_size, \n",
    "\t\tlatent_dim, \n",
    "\t\tepochs, \n",
    "\t\toptimizer,\n",
    "\t\t\t)\t\n",
    "\t# Callbacks for training\n",
    "model_callbacks = get_callbacks(RVE, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "results = RVE.fit(x_train, y_train,\n",
    "\t\t\tshuffle=True,\n",
    "\t\t\tepochs=epochs,\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tvalidation_data= (x_val, y_val),\n",
    "\t\t\tcallbacks=model_callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
